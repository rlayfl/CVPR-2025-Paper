% CVPR 2025 Paper Template; see https://github.com/cvpr-org/author-kit

\documentclass[10pt,twocolumn,letterpaper]{article}

%%%%%%%%% PAPER TYPE  - PLEASE UPDATE FOR FINAL VERSION
% \usepackage{cvpr}              % To produce the CAMERA-READY version
\usepackage[review]{cvpr}      % To produce the REVIEW version
% \usepackage[pagenumbers]{cvpr} % To force page numbers, e.g. for an arXiv version

% Import additional packages in the preamble file, before hyperref
\input{preamble}

% It is strongly recommended to use hyperref, especially for the review version.
% hyperref with option pagebackref eases the reviewers' job.
% Please disable hyperref *only* if you encounter grave issues, 
% e.g. with the file validation for the camera-ready version.
%
% If you comment hyperref and then uncomment it, you should delete *.aux before re-running LaTeX.
% (Or just hit 'q' on the first LaTeX run, let it finish, and you should be clear).
\definecolor{cvprblue}{rgb}{0.21,0.49,0.74}
\usepackage[pagebackref,breaklinks,colorlinks,allcolors=cvprblue]{hyperref}

%%%%%%%%% PAPER ID  - PLEASE UPDATE
\def\paperID{*****} % *** Enter the Paper ID here
\def\confName{CVPR}
\def\confYear{2025}

%%%%%%%%% TITLE - PLEASE UPDATE
\title{Large-scale Synthetic Data Generation of Ocean Marker Buoys with Unreal Engine 5}

%%%%%%%%% AUTHORS - PLEASE UPDATE
\author{First Author\\
Institution1\\
Institution1 address\\
{\tt\small firstauthor@i1.org}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
\and
Second Author\\
Institution2\\
First line of institution2 address\\
{\tt\small secondauthor@i2.org}
}

\begin{document}
\maketitle

\begin{abstract}
    The ABSTRACT is to be in fully justified italicized text, at the top of the left-hand column, below the author and affiliation information.
    Use the word ``Abstract'' as the title, in 12-point Times, boldface type, centered relative to the column, initially capitalized.
    The abstract is to be in 10-point, single-spaced type.
    Leave two blank lines after the Abstract, then begin the main text.
    Look at previous \confName abstracts to get a feel for style and length.
    \end{abstract}

\section{Introduction}


and discusses the method used for generating labels for the synthetic data. The paper also discusses the applications of the synthetic data, such as training object detection models. The paper concludes with a discussion of future work. 

The data produced should be as realistic as possible to ensure that the models trained on it are able to be applied to real world data. The method for achieving high fidelity data is discussed in \ref{sec:achieving_high_fidelity}.

\section{Literature Review}

The generation of synthetic data for machine learning tasks has taken place for many years. It takes place to save time, reduce risk and increase the scope of the data produced. One such study identified a benefit in generating synthetic data of car crashes for predicting dangerous vehicles, reducing the missed detection rate by 18.5\% compared to real data only models. \cite{Kim_Lee_Hwang_Suh_2019} 

However, synthetic data generation can often lead to data which is too clean looking and missing the imperfections of the real world, such as natural variation, deformation and clutter. \cite{Feng_2024_CVPR}

\section{Benefits of Synthetic Data Generation of Marker Buoys}

\subsection{Efficiency}

To test the efficiency of the pipeline, a total of 1000 images were generated. With an initial delay of 5 seconds to allow the simulation to properly load and with a time taken of 2 seconds per image, the total time taken to generate the images was 33 minutes and 25 seconds. This does not include the time taken to generate the environment or the buoys, which was done separately.

At a resolution of 512x512, around 600MB in data was generated, consisting of images with varying backgrounds, camera positions, lighting and weather conditions. This method frees up time for researches to focus on other tasks such as building the environments and sourcing realistic 3D models and textures. 

\subsection{Vast Scope of Possible Scenarios}

Unreal Engine 5 allows for the creation of realistic environments in basically any setting, if one can source the correct assets. This allows for the generation of data which covers scenarios which might be difficult or impossible to capture in the real world. For example, it allows for the generation of data in dangerous conditions or in conditions which are difficult to access.

\section{Methodology}

\subsection{Achieving High Fidelity} \label {sec:achieving_high_fidelity}



Aside from being an efficient method of generating synthetic data, the contents of the data can be completely controlled. There are no hallucinations to deal with and temporal consistency is maintained throughout the data. Once high 


\section{The Environment}

A benefit of using Unreal Engine 5 is the ability to create realistic and varied environments which can 


\subsection{The Water} \label {sec:the_water}

The water in the simulation is provided by Unreal Engine 5's Water plugin, more specifically the Water Body Ocean class. This water is simulated at interactive rates as a fluid, with the ability to simulate waves and the results of environment effects such as colour and lighting. With the fluid being simulated in real time, the water is able to be interacted with by actors in the scene, such as the buoys, as discussed in \ref{sec:the_buoys}.

Wave simulation is achieved through the use of a trochoidal or Gerstner wave function \cite{constantin2017gerstner}.

A terrain is required for fluid simulation.

\subsection{The Terrain}

Terrain, with the purpose of appearing in scenes (and not just as a requirement for fluid simulation as discussed in section \ref{sec:the_water}), was created using one of two methods.

Two methods were experimented with for creating the terrain. The first was to make use of assets available on the Unreal Engine marketplace, most notably the Megascans library \cite{QuixelMegascans}. This methods has the benefit of allowing the developer to create a realistic environment which can be travelled. However, a major downside is that assets often cost money and it can take a long time to create a realistic environment.

The second method was to use high dynamic range images (HDRI) to create the illusion of terrain, which normally provided a realistic sky too as a bonus. This method allowed for near instant creation of a realistic environment, giving the illusion of entire lakes with mountains in the background. However, the downside is that as the image is projected in a dome around a central point, moving even small distances away from the central point can cause the illusion to be broken. For this task, HDRI-based environments were suitable as the camera was moving only short distances around a static point.

\subsection{The Sky}

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{images/ultra_dynamic_sky.png}
    \caption{An example of the sky generated using the Ultra Dynamic Sky plugin in Unreal Engine 5.}
    \label{fig:sky_example}
\end{figure}

As with the terrain, two methods were experimented with for generating a realistic sky. The first was to use a plugin called Ultra Dynamic Sky \cite{UltraDynamicSky} which provided scene-wide realistic sky scapes and weather conditions. The second was to use a high dynamic range image (HDRI) to create the illusion of a sky. This method works well for static scenes in which minimal movement is required.


\subsection{The Weather}

Ultra dynamic weather

\section{The Buoys}

\subsection{Introduction}

\subsection{The Buoys} \label{sec:the_buoys}

The buoys are included in the scene as actors with static meshes, which play the part of digital twins of real marker buoys. The buoys 

\subsection{Buoyancy}

Pontoons

\section{The Data Generation Pipeline}

\subsection{Introduction}

Having a realistic environment is great and can be a lot of fun to make. However, it does not achieve the end goal of this project. Actually having data which can be used to train models, with minimal input from users is the goal. This section discusses the pipeline, alias SyntheticDataGenerationSystem used to generate the data.

Included as an actor in the world. 

\subsection{Handling Concurrent Actions} \label {sec:handling_concurrent_actions}

With the simulation being run in a video game engine, everything happens at interactive rates based on the frame rate of the simulation. Initially, a fundamental misunderstanding of how game engines work hindered progress. To summarise, as soon as the simulation began, all of the code written was executed in a single frame, causing n number of screenshots to be taken in an instant. The correct solution was to make use of Unreal Engine's Timer Handle (FTimerHandle) function, to schedule the taking of screenshots at a set interval.

To schedule the events, a cumulative delay was added to the timer handle in the form of:

cumulativeDelay = initialDelay + (markerBuoyNumber * numberOfVisits + visitNumber) * visitInterval;

Wait 5 seconds 

Position the camera

Take a screenshot



\subsection{Positioning the Camera}

To replicate the position of a camera as if it were on some sort of vessel, randomisation of the camera's position was included.

\subsection{Automating Screenshot Capture}

By making use of FTimerHandle, as mentioned in \ref{sec:handling_concurrent_actions}, screenshots could be taken at set intervals. 

\subsection{Generating Labels}

Two methods for generating labels were used. The first was to generate bounding boxes around the buoys in the scene using the inbuilt head's up display (HUD) feature. The second was to generate masks of the buoys in the scene. 

\subsection{Bounding Boxes}

Bounding boxes were generated by detecting points on the screen, per frame, which intersected with the buoy's static mesh. The bounding box was then generated by drawing a rectangle around the most northern, easter, southern and western points on the screen (see figure \ref{fig:buoy_with_bounding_box}). This method proved to be ineffective in generating tight bounding boxes around the buoys.

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{images/buoy_with_bounding_box.png}
    \caption{A buoy in the scene with a bounding box which is slightly too big.}
    \label{fig:buoy_with_bounding_box}
\end{figure}

\subsection{Masks}

To generate masks of the buoys in the scene, the following steps were taken:

\begin{enumerate}
    \item Set buoy to be displayed as a uniform and unique colour
    \item Take a screenshot of the scene
    \item Use custom python script to get the coordinates of the mask
\end{enumerate}

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{images/buoy_without_mask.png}
    \caption{A buoy in the scene without a mask.}
    \label{fig:buoy_without_mask}
\end{figure}

\section{Results}




\section{Applications}

The main application of this work is for generating data to train object detection models. 

\section{Conclusion}

\section{Future Work}

Some sort of fail safe to ensure that the generation can recover if some issues occur such as a power cut.

{
    \small
    \bibliographystyle{ieeenat_fullname}
    \bibliography{main}
}

% WARNING: do not forget to delete the supplementary pages from your submission 
% \input{sec/X_suppl}

\end{document}
